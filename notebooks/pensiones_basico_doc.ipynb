{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Documentación del flujo pensiones_basico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edf63645",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864eb218",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c88c57f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b722a5",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "282c34b9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9c575f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baece7df",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65ada7b4",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e136b1c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540146fe",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8d121bd",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "969101b8",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e32090f6",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e10c6fc7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3354bd",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "308f42b6",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ded3f0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae924659",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43226197",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08bd4023",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0875820",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2394df64",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdaff349",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ce5b3b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819e9e46",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d6bcf84",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b37e23b8",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec8aa631",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "920a33d0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e5fafea",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fc612a9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21992ad",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2637f2f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a36c197c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec111f1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a84d9a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da46ac87",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d10eba",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e91d6ae",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d400da4b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f404cc82",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b334889",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "005d6a73",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb9a7ef2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52666be7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28014e15",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b276c254",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b54328a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5acbd4f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ccff3e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "421e0660",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "610c7460",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affb17ed",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7163247",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98c344bb",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "041d2632",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "319bc077",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18cf1d60",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819518fa",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 1: Importamos las librerías necesarias para descarga, limpieza y análisis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import entropy as shannon_entropy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf, month_plot, quarter_plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 2: Definimos la fuente del API y descargamos todas las páginas del dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reportado: 89769\n",
            "Descargadas: 50000 filas…\n",
            "Descargadas: 100000 filas…\n"
          ]
        }
      ],
      "source": [
        "BASE = \"https://www.datos.gov.co\"\n",
        "RESOURCE = \"uawh-cjvi\"\n",
        "URL = f\"{BASE}/resource/{RESOURCE}.json\"\n",
        "\n",
        "try:\n",
        "    total_filas = int(requests.get(f\"{URL}?$select=count(*)\", timeout=60).json()[0][\"count\"])\n",
        "except Exception:\n",
        "    total_filas = None\n",
        "\n",
        "print(\"Total reportado:\", total_filas)\n",
        "\n",
        "Lista_paginas = []\n",
        "limit = 50000\n",
        "offset = 0\n",
        "\n",
        "while True:\n",
        "    params = {\"$limit\": limit, \"$offset\": offset}\n",
        "    r = requests.get(URL, params=params, timeout=120)\n",
        "    r.raise_for_status()\n",
        "    pagina = r.json()\n",
        "    if not pagina:\n",
        "        break\n",
        "    Lista_paginas.append(pd.DataFrame(pagina))\n",
        "    offset += limit\n",
        "    print(f\"Descargadas: {offset} filas…\")\n",
        "    time.sleep(0.3)\n",
        "\n",
        "if Lista_paginas:\n",
        "    df = pd.concat(Lista_paginas, ignore_index=True)\n",
        "else:\n",
        "    df = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 3: Convertimos las columnas clave a tipos adecuados y rellenamos valores faltantes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fecha                datetime64[ns]\n",
            "codigo_entidad               object\n",
            "nombre_entidad               object\n",
            "codigo_patrimonio            object\n",
            "nombre_fondo                 object\n",
            "valor_unidad                float64\n",
            "dtype: object\n",
            "fecha                0\n",
            "codigo_entidad       0\n",
            "nombre_entidad       0\n",
            "codigo_patrimonio    0\n",
            "nombre_fondo         0\n",
            "valor_unidad         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df[\"fecha\"] = pd.to_datetime(df[\"fecha\"], errors=\"coerce\")\n",
        "\n",
        "df[\"valor_unidad\"] = (\n",
        "    df[\"valor_unidad\"]\n",
        "      .astype(str)\n",
        "      .str.replace(r\"[^\\d\\-,\\.]\", \"\", regex=True)\n",
        "      .str.replace(\",\", \".\", regex=False)\n",
        "      .astype(float)\n",
        ")\n",
        "\n",
        "print(df.dtypes)\n",
        "print(df.isnull().sum())\n",
        "\n",
        "df[\"valor_unidad\"] = df[\"valor_unidad\"].ffill()\n",
        "df[\"valor_unidad\"] = df[\"valor_unidad\"].interpolate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 4: Exploramos nulos, cardinalidad y distribuciones básicas de entidades y fondos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fecha                0.0\n",
            "codigo_entidad       0.0\n",
            "nombre_entidad       0.0\n",
            "codigo_patrimonio    0.0\n",
            "nombre_fondo         0.0\n",
            "valor_unidad         0.0\n",
            "dtype: float64\n",
            "valor_unidad         88973\n",
            "fecha                 3591\n",
            "codigo_patrimonio        7\n",
            "nombre_fondo             7\n",
            "codigo_entidad           4\n",
            "nombre_entidad           4\n",
            "dtype: int64\n",
            "Valores únicos en nombre_entidad: ['\"Proteccion\"' '\"Porvenir\"' 'Skandia Afp - Accai S.A.'\n",
            " '\"Colfondos S.A.\" Y \"Colfondos\"']\n",
            "Valores únicos en nombre_fondo: ['Fondo de Cesantias Largo Plazo' 'Fondo de Cesantias Corto Plazo'\n",
            " 'Fondo de Pensiones Moderado' 'Fondo de Pensiones Conservador'\n",
            " 'Fondo de Pensiones Mayor Riesgo' 'Fondo de Pensiones Retiro Programado'\n",
            " 'Fondo de Pensiones Alternativo']\n",
            "Conteo nombre_entidad:\n",
            "nombre_entidad\n",
            "Skandia Afp - Accai S.A.          25137\n",
            "\"Porvenir\"                        21546\n",
            "\"Colfondos S.A.\" Y \"Colfondos\"    21546\n",
            "\"Proteccion\"                      21540\n",
            "Name: count, dtype: int64\n",
            "Conteo nombre_fondo:\n",
            "nombre_fondo\n",
            "Fondo de Cesantias Largo Plazo          14363\n",
            "Fondo de Cesantias Corto Plazo          14363\n",
            "Fondo de Pensiones Moderado             14363\n",
            "Fondo de Pensiones Conservador          14363\n",
            "Fondo de Pensiones Mayor Riesgo         14363\n",
            "Fondo de Pensiones Retiro Programado    14363\n",
            "Fondo de Pensiones Alternativo           3591\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "nulls = df.isna().mean().sort_values(ascending=False).mul(100).round(2)\n",
        "print(nulls)\n",
        "\n",
        "cardinalidad = df.nunique(dropna=True).sort_values(ascending=False)\n",
        "print(cardinalidad)\n",
        "\n",
        "print(\"Valores únicos en nombre_entidad:\", df[\"nombre_entidad\"].dropna().unique()[:10])\n",
        "print(\"Valores únicos en nombre_fondo:\", df[\"nombre_fondo\"].dropna().unique()[:10])\n",
        "print(\"Conteo nombre_entidad:\")\n",
        "print(df[\"nombre_entidad\"].value_counts(dropna=False).head(10))\n",
        "print(\"Conteo nombre_fondo:\")\n",
        "print(df[\"nombre_fondo\"].value_counts(dropna=False).head(20))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 5: Exportamos versiones limpias y diccionarios de referencia a CSV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "Path(\"data/raw\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "df_clean = df.drop(columns=[\"codigo_entidad\", \"codigo_patrimonio\"], errors=\"ignore\")\n",
        "df_clean.to_csv(\"data/raw/pensionesLimpio.csv\", index=False)\n",
        "\n",
        "if \"codigo_entidad\" in df.columns:\n",
        "    dict_entidad = (\n",
        "        df[[\"nombre_entidad\", \"codigo_entidad\"]]\n",
        "          .drop_duplicates()\n",
        "          .set_index(\"nombre_entidad\")[\"codigo_entidad\"]\n",
        "          .to_dict()\n",
        "    )\n",
        "    df[[\"nombre_entidad\", \"codigo_entidad\"]].drop_duplicates().to_csv(\n",
        "        \"data/raw/entidad_codigo.csv\", index=False\n",
        "    )\n",
        "else:\n",
        "    dict_entidad = {}\n",
        "\n",
        "if \"codigo_patrimonio\" in df.columns:\n",
        "    dict_fondo = (\n",
        "        df[[\"nombre_fondo\", \"codigo_patrimonio\"]]\n",
        "          .drop_duplicates()\n",
        "          .set_index(\"nombre_fondo\")[\"codigo_patrimonio\"]\n",
        "          .to_dict()\n",
        "    )\n",
        "    df[[\"nombre_fondo\", \"codigo_patrimonio\"]].drop_duplicates().to_csv(\n",
        "        \"data/raw/fondos_codigo.csv\", index=False\n",
        "    )\n",
        "else:\n",
        "    dict_fondo = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 6: Normalizamos textos y verificamos relaciones uno a uno entre códigos y nombres.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cardinalidad después de limpieza:\n",
            "nombre_entidad    4\n",
            "nombre_fondo      7\n",
            "dtype: int64\n",
            "Relación código_entidad → nombre_entidad:\n",
            "codigo_entidad\n",
            "10    1\n",
            "2     1\n",
            "3     1\n",
            "9     1\n",
            "Name: nombre_entidad, dtype: int64\n",
            "Relación nombre_entidad → código_entidad:\n",
            "nombre_entidad\n",
            "\"Colfondos S.A.\" Y \"Colfondos\"    1\n",
            "\"Porvenir\"                        1\n",
            "\"Proteccion\"                      1\n",
            "Skandia Afp - Accai S.A.          1\n",
            "Name: codigo_entidad, dtype: int64\n",
            "Relación código_patrimonio → nombre_fondo:\n",
            "codigo_patrimonio\n",
            "1       1\n",
            "1000    1\n",
            "2       1\n",
            "5000    1\n",
            "6000    1\n",
            "Name: nombre_fondo, dtype: int64\n",
            "Relación nombre_fondo → código_patrimonio:\n",
            "nombre_fondo\n",
            "Fondo de Cesantias Corto Plazo     1\n",
            "Fondo de Cesantias Largo Plazo     1\n",
            "Fondo de Pensiones Alternativo     1\n",
            "Fondo de Pensiones Conservador     1\n",
            "Fondo de Pensiones Mayor Riesgo    1\n",
            "Name: codigo_patrimonio, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "for columna in [\"nombre_entidad\", \"nombre_fondo\"]:\n",
        "    if columna in df.columns:\n",
        "        df[columna] = (\n",
        "            df[columna]\n",
        "              .astype(str)\n",
        "              .str.strip()\n",
        "              .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "        )\n",
        "\n",
        "print(\"Cardinalidad después de limpieza:\")\n",
        "print(df[[\"nombre_entidad\", \"nombre_fondo\"]].nunique())\n",
        "\n",
        "if \"codigo_entidad\" in df.columns:\n",
        "    print(\"Relación código_entidad → nombre_entidad:\")\n",
        "    print(df.groupby(\"codigo_entidad\")[\"nombre_entidad\"].nunique().sort_values(ascending=False).head())\n",
        "    print(\"Relación nombre_entidad → código_entidad:\")\n",
        "    print(df.groupby(\"nombre_entidad\")[\"codigo_entidad\"].nunique().sort_values(ascending=False).head())\n",
        "\n",
        "if \"codigo_patrimonio\" in df.columns:\n",
        "    print(\"Relación código_patrimonio → nombre_fondo:\")\n",
        "    print(df.groupby(\"codigo_patrimonio\")[\"nombre_fondo\"].nunique().sort_values(ascending=False).head())\n",
        "    print(\"Relación nombre_fondo → código_patrimonio:\")\n",
        "    print(df.groupby(\"nombre_fondo\")[\"codigo_patrimonio\"].nunique().sort_values(ascending=False).head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 7: Contamos y eliminamos duplicados exactos y conceptuales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ANÁLISIS DE DUPLICADOS ===\n",
            "Filas duplicadas exactas: 0\n",
            "✓ No hay duplicados exactos\n",
            "Duplicados entidad-fondo-fecha: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"=== ANÁLISIS DE DUPLICADOS ===\")\n",
        "duplicados = df.duplicated().sum()\n",
        "print(f\"Filas duplicadas exactas: {duplicados}\")\n",
        "if duplicados > 0:\n",
        "    df = df.drop_duplicates()\n",
        "    print(f\"Dataset después de eliminar duplicados exactos: {len(df)} filas\")\n",
        "else:\n",
        "    print(\"✓ No hay duplicados exactos\")\n",
        "\n",
        "duplicados_conceptuales = df.duplicated(subset=[\"nombre_entidad\", \"nombre_fondo\", \"fecha\"]).sum()\n",
        "print(f\"Duplicados entidad-fondo-fecha: {duplicados_conceptuales}\")\n",
        "if duplicados_conceptuales > 0:\n",
        "    df = df.drop_duplicates(subset=[\"nombre_entidad\", \"nombre_fondo\", \"fecha\"], keep=\"first\")\n",
        "    print(f\"Dataset después de limpieza: {len(df)} filas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 8: Detectamos outliers con IQR y etiquetamos la columna es_outlier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Límite inferior (outliers): 3481.55\n",
            "Límite superior (outliers): 84213.85\n",
            "Total de outliers detectados: 2475\n",
            "               nombre_entidad                    nombre_fondo      fecha  \\\n",
            "18   Skandia Afp - Accai S.A.  Fondo de Pensiones Alternativo 2016-01-01   \n",
            "43   Skandia Afp - Accai S.A.  Fondo de Pensiones Alternativo 2016-01-02   \n",
            "68   Skandia Afp - Accai S.A.  Fondo de Pensiones Alternativo 2016-01-03   \n",
            "93   Skandia Afp - Accai S.A.  Fondo de Pensiones Alternativo 2016-01-04   \n",
            "118  Skandia Afp - Accai S.A.  Fondo de Pensiones Alternativo 2016-01-05   \n",
            "\n",
            "     valor_unidad  \n",
            "18        2637.30  \n",
            "43        2637.63  \n",
            "68        2637.93  \n",
            "93        2629.92  \n",
            "118       2627.32  \n"
          ]
        }
      ],
      "source": [
        "Q1 = df[\"valor_unidad\"].quantile(0.25)\n",
        "Q3 = df[\"valor_unidad\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "limite_inferior = Q1 - 1.5 * IQR\n",
        "limite_superior = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df[(df[\"valor_unidad\"] < limite_inferior) | (df[\"valor_unidad\"] > limite_superior)]\n",
        "\n",
        "print(f\"Límite inferior (outliers): {limite_inferior:.2f}\")\n",
        "print(f\"Límite superior (outliers): {limite_superior:.2f}\")\n",
        "print(f\"Total de outliers detectados: {len(outliers)}\")\n",
        "\n",
        "if len(outliers) > 0:\n",
        "    print(outliers[[\"nombre_entidad\", \"nombre_fondo\", \"fecha\", \"valor_unidad\"]].head())\n",
        "    df[\"es_outlier\"] = False\n",
        "    df.loc[outliers.index, \"es_outlier\"] = True\n",
        "else:\n",
        "    df[\"es_outlier\"] = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 9: Optimizamos tipos y generamos variables temporales y tipo_fondo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    año  mes  trimestre tipo_fondo\n",
            "0  2016    1          1  Cesantías\n",
            "1  2016    1          1  Cesantías\n",
            "2  2016    1          1  Pensiones\n",
            "3  2016    1          1  Pensiones\n",
            "4  2016    1          1  Pensiones\n"
          ]
        }
      ],
      "source": [
        "df[\"nombre_entidad\"] = df[\"nombre_entidad\"].astype(\"category\")\n",
        "df[\"nombre_fondo\"] = df[\"nombre_fondo\"].astype(\"category\")\n",
        "df[\"es_outlier\"] = df[\"es_outlier\"].astype(bool)\n",
        "\n",
        "df[\"año\"] = df[\"fecha\"].dt.year\n",
        "df[\"mes\"] = df[\"fecha\"].dt.month\n",
        "df[\"trimestre\"] = df[\"fecha\"].dt.quarter\n",
        "\n",
        "def clasificar_fondo(nombre):\n",
        "    nombre = str(nombre).lower()\n",
        "    if \"cesantia\" in nombre:\n",
        "        return \"Cesantías\"\n",
        "    if \"pension\" in nombre:\n",
        "        return \"Pensiones\"\n",
        "    if \"alternativo\" in nombre:\n",
        "        return \"Alternativo\"\n",
        "    return \"Otros\"\n",
        "\n",
        "df[\"tipo_fondo\"] = df[\"nombre_fondo\"].apply(clasificar_fondo).astype(\"category\")\n",
        "print(df[[\"año\", \"mes\", \"trimestre\", \"tipo_fondo\"]].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 10: Definimos guardar_subset y exportamos subconjuntos por entidad y fondo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data/raw/skandia.csv (25137, 10)\n",
            "data/raw/skandia_fondo_cesantias_largo_plazo.csv (3591, 9)\n",
            "data/raw/skandia_fondo_cesantias_corto_plazo.csv (3591, 9)\n",
            "data/raw/skandia_fondo_pensiones_moderado.csv (3591, 9)\n",
            "data/raw/skandia_fondo_pensiones_conservador.csv (3591, 9)\n",
            "data/raw/skandia_fondo_pensiones_mayor_riesgo.csv (3591, 9)\n",
            "data/raw/skandia_fondo_pensiones_retiro_programado.csv (3591, 9)\n",
            "data/raw/skandia_fondo_pensiones_alternativo.csv (3591, 9)\n",
            "data/raw/proteccion.csv (21540, 10)\n",
            "data/raw/proteccion_fondo_cesantias_largo_plazo.csv (3590, 9)\n",
            "data/raw/proteccion_fondo_cesantias_corto_plazo.csv (3590, 9)\n",
            "data/raw/proteccion_fondo_pensiones_moderado.csv (3590, 9)\n",
            "data/raw/proteccion_fondo_pensiones_conservador.csv (3590, 9)\n",
            "data/raw/proteccion_fondo_pensiones_mayor_riesgo.csv (3590, 9)\n",
            "data/raw/proteccion_fondo_pensiones_retiro_programado.csv (3590, 9)\n",
            "data/raw/proteccion_fondo_pensiones_alternativo.csv (0, 9)\n",
            "data/raw/porvenir.csv (21546, 10)\n",
            "data/raw/porvenir_fondo_cesantias_largo_plazo.csv (3591, 9)\n",
            "data/raw/porvenir_fondo_cesantias_corto_plazo.csv (3591, 9)\n",
            "data/raw/porvenir_fondo_pensiones_moderado.csv (3591, 9)\n",
            "data/raw/porvenir_fondo_pensiones_conservador.csv (3591, 9)\n",
            "data/raw/porvenir_fondo_pensiones_mayor_riesgo.csv (3591, 9)\n",
            "data/raw/porvenir_fondo_pensiones_retiro_programado.csv (3591, 9)\n",
            "data/raw/porvenir_fondo_pensiones_alternativo.csv (0, 9)\n",
            "data/raw/colfondos.csv (21546, 10)\n",
            "data/raw/colfondos_fondo_cesantias_largo_plazo.csv (3591, 9)\n",
            "data/raw/colfondos_fondo_cesantias_corto_plazo.csv (3591, 9)\n",
            "data/raw/colfondos_fondo_pensiones_moderado.csv (3591, 9)\n",
            "data/raw/colfondos_fondo_pensiones_conservador.csv (3591, 9)\n",
            "data/raw/colfondos_fondo_pensiones_mayor_riesgo.csv (3591, 9)\n",
            "data/raw/colfondos_fondo_pensiones_retiro_programado.csv (3591, 9)\n",
            "data/raw/colfondos_fondo_pensiones_alternativo.csv (0, 9)\n"
          ]
        }
      ],
      "source": [
        "def guardar_subset(dataframe, columna, valores, ruta_salida):\n",
        "    if isinstance(valores, (list, tuple, set)):\n",
        "        df_subset = dataframe.loc[dataframe[columna].isin(valores)].copy()\n",
        "    else:\n",
        "        df_subset = dataframe.loc[dataframe[columna].eq(valores)].copy()\n",
        "    if columna in df_subset.columns:\n",
        "        df_subset = df_subset.drop(columns=[columna])\n",
        "    df_subset.to_csv(ruta_salida, index=False)\n",
        "    print(ruta_salida, df_subset.shape)\n",
        "    return df_subset\n",
        "\n",
        "# Subconjuntos Skandia\n",
        "df_skandia = guardar_subset(df, \"nombre_entidad\", \"Skandia Afp - Accai S.A.\", \"data/raw/skandia.csv\")\n",
        "df_skandia_cesantias_largo_plazo = guardar_subset(df_skandia, \"nombre_fondo\", \"Fondo de Cesantias Largo Plazo\", \"data/raw/skandia_fondo_cesantias_largo_plazo.csv\")\n",
        "df_skandia_cesantias_corto_plazo = guardar_subset(df_skandia, \"nombre_fondo\", \"Fondo de Cesantias Corto Plazo\", \"data/raw/skandia_fondo_cesantias_corto_plazo.csv\")\n",
        "df_skandia_pensiones_moderado = guardar_subset(df_skandia, \"nombre_fondo\", \"Fondo de Pensiones Moderado\", \"data/raw/skandia_fondo_pensiones_moderado.csv\")\n",
        "df_skandia_pensiones_conservador = guardar_subset(df_skandia, \"nombre_fondo\", \"Fondo de Pensiones Conservador\", \"data/raw/skandia_fondo_pensiones_conservador.csv\")\n",
        "df_skandia_pensiones_mayor_riesgo = guardar_subset(df_skandia, \"nombre_fondo\", \"Fondo de Pensiones Mayor Riesgo\", \"data/raw/skandia_fondo_pensiones_mayor_riesgo.csv\")\n",
        "df_skandia_pensiones_retiro_programado = guardar_subset(df_skandia, \"nombre_fondo\", \"Fondo de Pensiones Retiro Programado\", \"data/raw/skandia_fondo_pensiones_retiro_programado.csv\")\n",
        "df_skandia_pensiones_alternativo = guardar_subset(df_skandia, \"nombre_fondo\", \"Fondo de Pensiones Alternativo\", \"data/raw/skandia_fondo_pensiones_alternativo.csv\")\n",
        "\n",
        "# Subconjuntos Protección\n",
        "df_proteccion = guardar_subset(df, \"nombre_entidad\", '\"Proteccion\"', \"data/raw/proteccion.csv\")\n",
        "df_proteccion_cesantias_largo_plazo = guardar_subset(df_proteccion, \"nombre_fondo\", \"Fondo de Cesantias Largo Plazo\", \"data/raw/proteccion_fondo_cesantias_largo_plazo.csv\")\n",
        "df_proteccion_cesantias_corto_plazo = guardar_subset(df_proteccion, \"nombre_fondo\", \"Fondo de Cesantias Corto Plazo\", \"data/raw/proteccion_fondo_cesantias_corto_plazo.csv\")\n",
        "df_proteccion_pensiones_moderado = guardar_subset(df_proteccion, \"nombre_fondo\", \"Fondo de Pensiones Moderado\", \"data/raw/proteccion_fondo_pensiones_moderado.csv\")\n",
        "df_proteccion_pensiones_conservador = guardar_subset(df_proteccion, \"nombre_fondo\", \"Fondo de Pensiones Conservador\", \"data/raw/proteccion_fondo_pensiones_conservador.csv\")\n",
        "df_proteccion_pensiones_mayor_riesgo = guardar_subset(df_proteccion, \"nombre_fondo\", \"Fondo de Pensiones Mayor Riesgo\", \"data/raw/proteccion_fondo_pensiones_mayor_riesgo.csv\")\n",
        "df_proteccion_pensiones_retiro_programado = guardar_subset(df_proteccion, \"nombre_fondo\", \"Fondo de Pensiones Retiro Programado\", \"data/raw/proteccion_fondo_pensiones_retiro_programado.csv\")\n",
        "df_proteccion_pensiones_alternativo = guardar_subset(df_proteccion, \"nombre_fondo\", \"Fondo de Pensiones Alternativo\", \"data/raw/proteccion_fondo_pensiones_alternativo.csv\")\n",
        "\n",
        "# Subconjuntos Porvenir\n",
        "df_porvenir = guardar_subset(df, \"nombre_entidad\", '\"Porvenir\"', \"data/raw/porvenir.csv\")\n",
        "df_porvenir_cesantias_largo_plazo = guardar_subset(df_porvenir, \"nombre_fondo\", \"Fondo de Cesantias Largo Plazo\", \"data/raw/porvenir_fondo_cesantias_largo_plazo.csv\")\n",
        "df_porvenir_cesantias_corto_plazo = guardar_subset(df_porvenir, \"nombre_fondo\", \"Fondo de Cesantias Corto Plazo\", \"data/raw/porvenir_fondo_cesantias_corto_plazo.csv\")\n",
        "df_porvenir_pensiones_moderado = guardar_subset(df_porvenir, \"nombre_fondo\", \"Fondo de Pensiones Moderado\", \"data/raw/porvenir_fondo_pensiones_moderado.csv\")\n",
        "df_porvenir_pensiones_conservador = guardar_subset(df_porvenir, \"nombre_fondo\", \"Fondo de Pensiones Conservador\", \"data/raw/porvenir_fondo_pensiones_conservador.csv\")\n",
        "df_porvenir_pensiones_mayor_riesgo = guardar_subset(df_porvenir, \"nombre_fondo\", \"Fondo de Pensiones Mayor Riesgo\", \"data/raw/porvenir_fondo_pensiones_mayor_riesgo.csv\")\n",
        "df_porvenir_pensiones_retiro_programado = guardar_subset(df_porvenir, \"nombre_fondo\", \"Fondo de Pensiones Retiro Programado\", \"data/raw/porvenir_fondo_pensiones_retiro_programado.csv\")\n",
        "df_porvenir_pensiones_alternativo = guardar_subset(df_porvenir, \"nombre_fondo\", \"Fondo de Pensiones Alternativo\", \"data/raw/porvenir_fondo_pensiones_alternativo.csv\")\n",
        "\n",
        "# Subconjuntos Colfondos\n",
        "df_colfondos = guardar_subset(df, \"nombre_entidad\", '\"Colfondos S.A.\" Y \"Colfondos\"', \"data/raw/colfondos.csv\")\n",
        "df_colfondos_cesantias_largo_plazo = guardar_subset(df_colfondos, \"nombre_fondo\", \"Fondo de Cesantias Largo Plazo\", \"data/raw/colfondos_fondo_cesantias_largo_plazo.csv\")\n",
        "df_colfondos_cesantias_corto_plazo = guardar_subset(df_colfondos, \"nombre_fondo\", \"Fondo de Cesantias Corto Plazo\", \"data/raw/colfondos_fondo_cesantias_corto_plazo.csv\")\n",
        "df_colfondos_pensiones_moderado = guardar_subset(df_colfondos, \"nombre_fondo\", \"Fondo de Pensiones Moderado\", \"data/raw/colfondos_fondo_pensiones_moderado.csv\")\n",
        "df_colfondos_pensiones_conservador = guardar_subset(df_colfondos, \"nombre_fondo\", \"Fondo de Pensiones Conservador\", \"data/raw/colfondos_fondo_pensiones_conservador.csv\")\n",
        "df_colfondos_pensiones_mayor_riesgo = guardar_subset(df_colfondos, \"nombre_fondo\", \"Fondo de Pensiones Mayor Riesgo\", \"data/raw/colfondos_fondo_pensiones_mayor_riesgo.csv\")\n",
        "df_colfondos_pensiones_retiro_programado = guardar_subset(df_colfondos, \"nombre_fondo\", \"Fondo de Pensiones Retiro Programado\", \"data/raw/colfondos_fondo_pensiones_retiro_programado.csv\")\n",
        "df_colfondos_pensiones_alternativo = guardar_subset(df_colfondos, \"nombre_fondo\", \"Fondo de Pensiones Alternativo\", \"data/raw/colfondos_fondo_pensiones_alternativo.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 11: Creamos gráficos comparativos por tipo de fondo entre entidades.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def graficar_comparacion_entidades_por_fondo(fondos_a_comparar, titulo_base, nombre_archivo):\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    colores = ['blue', 'red', 'green', 'orange', 'purple', 'brown']\n",
        "    for i, (entidad, df_fondo) in enumerate(fondos_a_comparar.items()):\n",
        "        if len(df_fondo) > 0:\n",
        "            color = colores[i % len(colores)]\n",
        "            plt.plot(df_fondo['fecha'], df_fondo['valor_unidad'], label=entidad, color=color, linewidth=2, alpha=0.8)\n",
        "    plt.title(f'{titulo_base} - Comparación por Entidad')\n",
        "    plt.xlabel('Fecha')\n",
        "    plt.ylabel('Valor Unidad')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    Path(\"data/graficas_comparativas\").mkdir(parents=True, exist_ok=True)\n",
        "    plt.savefig(f\"data/graficas_comparativas/{nombre_archivo}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "fondos_moderado = {\n",
        "    'Skandia': df_skandia_pensiones_moderado,\n",
        "    'Protección': df_proteccion_pensiones_moderado,\n",
        "    'Porvenir': df_porvenir_pensiones_moderado,\n",
        "    'Colfondos': df_colfondos_pensiones_moderado\n",
        "}\n",
        "graficar_comparacion_entidades_por_fondo(fondos_moderado, \"Fondo de Pensiones Moderado\", \"comparacion_pensiones_moderado\")\n",
        "\n",
        "fondos_conservador = {\n",
        "    'Skandia': df_skandia_pensiones_conservador,\n",
        "    'Protección': df_proteccion_pensiones_conservador,\n",
        "    'Porvenir': df_porvenir_pensiones_conservador,\n",
        "    'Colfondos': df_colfondos_pensiones_conservador\n",
        "}\n",
        "graficar_comparacion_entidades_por_fondo(fondos_conservador, \"Fondo de Pensiones Conservador\", \"comparacion_pensiones_conservador\")\n",
        "\n",
        "fondos_cesantias_largo = {\n",
        "    'Skandia': df_skandia_cesantias_largo_plazo,\n",
        "    'Protección': df_proteccion_cesantias_largo_plazo,\n",
        "    'Porvenir': df_porvenir_cesantias_largo_plazo,\n",
        "    'Colfondos': df_colfondos_cesantias_largo_plazo\n",
        "}\n",
        "graficar_comparacion_entidades_por_fondo(fondos_cesantias_largo, \"Fondo de Cesantías Largo Plazo\", \"comparacion_cesantias_largo\")\n",
        "\n",
        "fondos_cesantias_corto = {\n",
        "    'Skandia': df_skandia_cesantias_corto_plazo,\n",
        "    'Protección': df_proteccion_cesantias_corto_plazo,\n",
        "    'Porvenir': df_porvenir_cesantias_corto_plazo,\n",
        "    'Colfondos': df_colfondos_cesantias_corto_plazo\n",
        "}\n",
        "graficar_comparacion_entidades_por_fondo(fondos_cesantias_corto, \"Fondo de Cesantías Corto Plazo\", \"comparacion_cesantias_corto\")\n",
        "\n",
        "fondos_mayor_riesgo = {\n",
        "    'Skandia': df_skandia_pensiones_mayor_riesgo,\n",
        "    'Protección': df_proteccion_pensiones_mayor_riesgo,\n",
        "    'Porvenir': df_porvenir_pensiones_mayor_riesgo,\n",
        "    'Colfondos': df_colfondos_pensiones_mayor_riesgo\n",
        "}\n",
        "graficar_comparacion_entidades_por_fondo(fondos_mayor_riesgo, \"Fondo de Pensiones Mayor Riesgo\", \"comparacion_pensiones_mayor_riesgo\")\n",
        "\n",
        "fondos_retiro_programado = {\n",
        "    'Skandia': df_skandia_pensiones_retiro_programado,\n",
        "    'Protección': df_proteccion_pensiones_retiro_programado,\n",
        "    'Porvenir': df_porvenir_pensiones_retiro_programado,\n",
        "    'Colfondos': df_colfondos_pensiones_retiro_programado\n",
        "}\n",
        "graficar_comparacion_entidades_por_fondo(fondos_retiro_programado, \"Fondo de Pensiones retiro programado\", \"comparacion_pensiones_retiro_programado\")\n",
        "\n",
        "fondos_alternativo = {\n",
        "    'Skandia': df_skandia_pensiones_alternativo,\n",
        "    'Protección': df_proteccion_pensiones_alternativo,\n",
        "    'Porvenir': df_porvenir_pensiones_alternativo,\n",
        "    'Colfondos': df_colfondos_pensiones_alternativo\n",
        "}\n",
        "graficar_comparacion_entidades_por_fondo(fondos_alternativo, \"Fondo de Pensiones alternativo\", \"comparacion_pensiones_alternativo\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 12: Analizamos evolución y correlaciones por entidad con funciones auxiliares.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cesantías Largo Plazo</th>\n",
              "      <th>Cesantías Corto Plazo</th>\n",
              "      <th>Pensiones Moderado</th>\n",
              "      <th>Pensiones Conservador</th>\n",
              "      <th>Pensiones Mayor Riesgo</th>\n",
              "      <th>Pensiones Retiro Programado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cesantías Largo Plazo</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.124827</td>\n",
              "      <td>0.955504</td>\n",
              "      <td>0.868332</td>\n",
              "      <td>0.944808</td>\n",
              "      <td>0.748912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cesantías Corto Plazo</th>\n",
              "      <td>0.124827</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.115030</td>\n",
              "      <td>0.222580</td>\n",
              "      <td>0.089369</td>\n",
              "      <td>0.216842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pensiones Moderado</th>\n",
              "      <td>0.955504</td>\n",
              "      <td>0.115030</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.834002</td>\n",
              "      <td>0.942904</td>\n",
              "      <td>0.737826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pensiones Conservador</th>\n",
              "      <td>0.868332</td>\n",
              "      <td>0.222580</td>\n",
              "      <td>0.834002</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.771402</td>\n",
              "      <td>0.884027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pensiones Mayor Riesgo</th>\n",
              "      <td>0.944808</td>\n",
              "      <td>0.089369</td>\n",
              "      <td>0.942904</td>\n",
              "      <td>0.771402</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.649172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pensiones Retiro Programado</th>\n",
              "      <td>0.748912</td>\n",
              "      <td>0.216842</td>\n",
              "      <td>0.737826</td>\n",
              "      <td>0.884027</td>\n",
              "      <td>0.649172</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Cesantías Largo Plazo  Cesantías Corto Plazo  \\\n",
              "Cesantías Largo Plazo                     1.000000               0.124827   \n",
              "Cesantías Corto Plazo                     0.124827               1.000000   \n",
              "Pensiones Moderado                        0.955504               0.115030   \n",
              "Pensiones Conservador                     0.868332               0.222580   \n",
              "Pensiones Mayor Riesgo                    0.944808               0.089369   \n",
              "Pensiones Retiro Programado               0.748912               0.216842   \n",
              "\n",
              "                             Pensiones Moderado  Pensiones Conservador  \\\n",
              "Cesantías Largo Plazo                  0.955504               0.868332   \n",
              "Cesantías Corto Plazo                  0.115030               0.222580   \n",
              "Pensiones Moderado                     1.000000               0.834002   \n",
              "Pensiones Conservador                  0.834002               1.000000   \n",
              "Pensiones Mayor Riesgo                 0.942904               0.771402   \n",
              "Pensiones Retiro Programado            0.737826               0.884027   \n",
              "\n",
              "                             Pensiones Mayor Riesgo  \\\n",
              "Cesantías Largo Plazo                      0.944808   \n",
              "Cesantías Corto Plazo                      0.089369   \n",
              "Pensiones Moderado                         0.942904   \n",
              "Pensiones Conservador                      0.771402   \n",
              "Pensiones Mayor Riesgo                     1.000000   \n",
              "Pensiones Retiro Programado                0.649172   \n",
              "\n",
              "                             Pensiones Retiro Programado  \n",
              "Cesantías Largo Plazo                           0.748912  \n",
              "Cesantías Corto Plazo                           0.216842  \n",
              "Pensiones Moderado                              0.737826  \n",
              "Pensiones Conservador                           0.884027  \n",
              "Pensiones Mayor Riesgo                          0.649172  \n",
              "Pensiones Retiro Programado                     1.000000  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def evolucion_todos_fondos_entidad(entidad_nombre, dataframes_fondos):\n",
        "    plt.figure(figsize=(16, 10))\n",
        "    fondos_colores = {\n",
        "        'Cesantías Largo Plazo': 'blue',\n",
        "        'Cesantías Corto Plazo': 'lightblue',\n",
        "        'Pensiones Moderado': 'green',\n",
        "        'Pensiones Conservador': 'darkgreen',\n",
        "        'Pensiones Mayor Riesgo': 'red',\n",
        "        'Pensiones Retiro Programado': 'orange',\n",
        "        'Pensiones Alternativo': 'purple'\n",
        "    }\n",
        "    for fondo_nombre, color in fondos_colores.items():\n",
        "        if fondo_nombre in dataframes_fondos and len(dataframes_fondos[fondo_nombre]) > 0:\n",
        "            df_temp = dataframes_fondos[fondo_nombre]\n",
        "            valor_base = df_temp['valor_unidad'].iloc[0]\n",
        "            df_normalizado = (df_temp['valor_unidad'] / valor_base * 100)\n",
        "            plt.plot(df_temp['fecha'], df_normalizado, label=fondo_nombre, color=color, linewidth=2, alpha=0.7)\n",
        "    plt.title(f'Evolución de Todos los Fondos - {entidad_nombre} (Base 100)')\n",
        "    plt.xlabel('Fecha')\n",
        "    plt.ylabel('Valor Normalizado')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    Path(\"data/graficas_comparativas\").mkdir(parents=True, exist_ok=True)\n",
        "    plt.savefig(f'data/graficas_comparativas/evolucion_todos_fondos_{entidad_nombre.lower()}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def matriz_correlacion_fondos(entidad_nombre, dataframes_fondos):\n",
        "    datos_correlacion = {}\n",
        "    for fondo_nombre, df_temp in dataframes_fondos.items():\n",
        "        if len(df_temp) > 0:\n",
        "            serie = df_temp.set_index('fecha')['valor_unidad'].sort_index()\n",
        "            returns = serie.pct_change().dropna()\n",
        "            datos_correlacion[fondo_nombre] = returns\n",
        "    df_correlacion = pd.DataFrame(datos_correlacion)\n",
        "    matriz_corr = df_correlacion.corr()\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    mask = np.triu(np.ones_like(matriz_corr, dtype=bool))\n",
        "    sns.heatmap(matriz_corr, mask=mask, annot=True, cmap='coolwarm', center=0, square=True, fmt='.2f', cbar_kws={'label': 'Coeficiente'})\n",
        "    plt.title(f'Matriz de Correlación - {entidad_nombre} (returns diarios)')\n",
        "    plt.tight_layout()\n",
        "    Path(\"data/graficas_comparativas\").mkdir(parents=True, exist_ok=True)\n",
        "    plt.savefig(f'data/graficas_comparativas/correlacion_{entidad_nombre.lower()}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    return matriz_corr\n",
        "\n",
        "entidades_dataframes = {\n",
        "    'Skandia': {\n",
        "        'Cesantías Largo Plazo': df_skandia_cesantias_largo_plazo,\n",
        "        'Cesantías Corto Plazo': df_skandia_cesantias_corto_plazo,\n",
        "        'Pensiones Moderado': df_skandia_pensiones_moderado,\n",
        "        'Pensiones Conservador': df_skandia_pensiones_conservador,\n",
        "        'Pensiones Mayor Riesgo': df_skandia_pensiones_mayor_riesgo,\n",
        "        'Pensiones Retiro Programado': df_skandia_pensiones_retiro_programado,\n",
        "        'Pensiones Alternativo': df_skandia_pensiones_alternativo\n",
        "    },\n",
        "    'Protección': {\n",
        "        'Cesantías Largo Plazo': df_proteccion_cesantias_largo_plazo,\n",
        "        'Cesantías Corto Plazo': df_proteccion_cesantias_corto_plazo,\n",
        "        'Pensiones Moderado': df_proteccion_pensiones_moderado,\n",
        "        'Pensiones Conservador': df_proteccion_pensiones_conservador,\n",
        "        'Pensiones Mayor Riesgo': df_proteccion_pensiones_mayor_riesgo,\n",
        "        'Pensiones Retiro Programado': df_proteccion_pensiones_retiro_programado,\n",
        "        'Pensiones Alternativo': df_proteccion_pensiones_alternativo\n",
        "    },\n",
        "    'Porvenir': {\n",
        "        'Cesantías Largo Plazo': df_porvenir_cesantias_largo_plazo,\n",
        "        'Cesantías Corto Plazo': df_porvenir_cesantias_corto_plazo,\n",
        "        'Pensiones Moderado': df_porvenir_pensiones_moderado,\n",
        "        'Pensiones Conservador': df_porvenir_pensiones_conservador,\n",
        "        'Pensiones Mayor Riesgo': df_porvenir_pensiones_mayor_riesgo,\n",
        "        'Pensiones Retiro Programado': df_porvenir_pensiones_retiro_programado,\n",
        "        'Pensiones Alternativo': df_porvenir_pensiones_alternativo\n",
        "    },\n",
        "    'Colfondos': {\n",
        "        'Cesantías Largo Plazo': df_colfondos_cesantias_largo_plazo,\n",
        "        'Cesantías Corto Plazo': df_colfondos_cesantias_corto_plazo,\n",
        "        'Pensiones Moderado': df_colfondos_pensiones_moderado,\n",
        "        'Pensiones Conservador': df_colfondos_pensiones_conservador,\n",
        "        'Pensiones Mayor Riesgo': df_colfondos_pensiones_mayor_riesgo,\n",
        "        'Pensiones Retiro Programado': df_colfondos_pensiones_retiro_programado,\n",
        "        'Pensiones Alternativo': df_colfondos_pensiones_alternativo\n",
        "    }\n",
        "}\n",
        "\n",
        "evolucion_todos_fondos_entidad('Skandia', entidades_dataframes['Skandia'])\n",
        "evolucion_todos_fondos_entidad('Protección', entidades_dataframes['Protección'])\n",
        "evolucion_todos_fondos_entidad('Porvenir', entidades_dataframes['Porvenir'])\n",
        "evolucion_todos_fondos_entidad('Colfondos', entidades_dataframes['Colfondos'])\n",
        "\n",
        "matriz_correlacion_fondos('Skandia', entidades_dataframes['Skandia'])\n",
        "matriz_correlacion_fondos('Protección', entidades_dataframes['Protección'])\n",
        "matriz_correlacion_fondos('Porvenir', entidades_dataframes['Porvenir'])\n",
        "matriz_correlacion_fondos('Colfondos', entidades_dataframes['Colfondos'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 13: Generamos columnas lag para comparaciones temporales de valor_unidad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_143348/1063748102.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'lag_{lag}'] = df['valor_unidad'].shift(lag)\n",
            "/tmp/ipykernel_143348/1063748102.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'lag_{lag}'] = df['valor_unidad'].shift(lag)\n",
            "/tmp/ipykernel_143348/1063748102.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'lag_{lag}'] = df['valor_unidad'].shift(lag)\n",
            "/tmp/ipykernel_143348/1063748102.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'lag_{lag}'] = df['valor_unidad'].shift(lag)\n",
            "/tmp/ipykernel_143348/1063748102.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'lag_{lag}'] = df['valor_unidad'].shift(lag)\n",
            "/tmp/ipykernel_143348/1063748102.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'lag_{lag}'] = df['valor_unidad'].shift(lag)\n",
            "/tmp/ipykernel_143348/1063748102.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'lag_{lag}'] = df['valor_unidad'].shift(lag)\n",
            "/tmp/ipykernel_143348/1063748102.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'lag_{lag}'] = df['valor_unidad'].shift(lag)\n"
          ]
        }
      ],
      "source": [
        "for lag in range(1, len(df) // 30, 30):\n",
        "    df[f'lag_{lag}'] = df['valor_unidad'].shift(lag)\n",
        "\n",
        "lags = [1, 7, 30, 90, 180, 365]\n",
        "lag_columns = {f'lag_{lag}': df['valor_unidad'].shift(lag) for lag in lags}\n",
        "lag_df = pd.DataFrame(lag_columns)\n",
        "df = pd.concat([df, lag_df], axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 14: Ejecutamos el EDA completo con estadísticas, gráficas y descomposición.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ANÁLISIS EXPLORATORIO COMPLETO (EDA) ===\n",
            "       valor_unidad\n",
            "count  89769.000000\n",
            "mean   44231.791309\n",
            "std    16417.473065\n",
            "min     2596.400000\n",
            "25%    33756.164041\n",
            "50%    42634.660000\n",
            "75%    53939.240000\n",
            "max    97821.910000\n",
            "              count          mean           std       min        25%  \\\n",
            "tipo_fondo                                                             \n",
            "Cesantías   28726.0  34101.995393   6832.263056  21589.17  28804.325   \n",
            "Pensiones   61043.0  48998.734570  17418.228534   2596.40  40042.200   \n",
            "\n",
            "                 50%       75%       max  \n",
            "tipo_fondo                                \n",
            "Cesantías   33367.67  38213.49  56380.17  \n",
            "Pensiones   48480.09  59657.30  97821.91  \n",
            "              mean           std      min       max\n",
            "año                                                \n",
            "2016  30933.310505   8090.679461  2596.40  44298.29\n",
            "2017  34684.921141   9449.220153  2848.70  49635.24\n",
            "2018  36858.466367  10147.320209  3135.23  51343.60\n",
            "2019  39836.324999  11367.830222  3263.69  58638.94\n",
            "2020  41744.940330  12139.707801  3326.61  63146.04\n",
            "2021  45862.244212  13958.715407  4159.91  68108.20\n",
            "2022  45694.008169  14110.650867  3972.21  68542.53\n",
            "2023  50239.193536  15666.772610  4323.94  81224.37\n",
            "2024  57296.267901  18011.200181  4691.97  86993.31\n",
            "2025  62247.787947  19719.326986  5321.51  97821.91\n",
            "EDA completado\n"
          ]
        }
      ],
      "source": [
        "Path(\"data/graficas_comparativas\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"=== ANÁLISIS EXPLORATORIO COMPLETO (EDA) ===\")\n",
        "print(df[['valor_unidad']].describe())\n",
        "print(df.groupby('tipo_fondo', observed=True)['valor_unidad'].describe())\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "df['valor_unidad'].hist(bins=50, alpha=0.7)\n",
        "plt.title('Distribución de valor_unidad')\n",
        "plt.subplot(1, 2, 2)\n",
        "df['valor_unidad'].plot(kind='density')\n",
        "plt.title('Densidad de valor_unidad')\n",
        "plt.tight_layout()\n",
        "plt.savefig('data/graficas_comparativas/distribucion_y_densidad_valor_unidad.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "evolucion_anual = df.groupby('año')['valor_unidad'].agg(['mean', 'std', 'min', 'max'])\n",
        "print(evolucion_anual)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(evolucion_anual.index, evolucion_anual['mean'], marker='o')\n",
        "plt.fill_between(evolucion_anual.index, evolucion_anual['mean'] - evolucion_anual['std'], evolucion_anual['mean'] + evolucion_anual['std'], alpha=0.2)\n",
        "plt.title('Evolución anual del valor unidad (media ± desviación)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('data/graficas_comparativas/evolucion_anual.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "fondo_ejemplo = df_skandia_pensiones_moderado.set_index('fecha')['valor_unidad']\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_acf(fondo_ejemplo, lags=30, ax=plt.gca())\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_pacf(fondo_ejemplo, lags=30, ax=plt.gca())\n",
        "plt.tight_layout()\n",
        "plt.savefig('data/graficas_comparativas/autocorrelacion.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "fondo_mensual = fondo_ejemplo.resample('ME').mean()\n",
        "try:\n",
        "    descomposicion = seasonal_decompose(fondo_mensual, model='additive', period=12)\n",
        "    fig = descomposicion.plot()\n",
        "    fig.set_size_inches(12, 8)\n",
        "    fig.suptitle('Descomposición estacional - Fondo moderado Skandia', fontsize=14)\n",
        "    plt.savefig('data/graficas_comparativas/descomposicion_estacional.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "except Exception as e:\n",
        "    print('Error en descomposición estacional:', e)\n",
        "\n",
        "estacionalidad_mensual = df.groupby('mes')['valor_unidad'].mean()\n",
        "plt.figure(figsize=(10, 6))\n",
        "estacionalidad_mensual.plot(kind='bar', color='skyblue', alpha=0.7)\n",
        "plt.title('Comportamiento estacional promedio por mes')\n",
        "plt.savefig('data/graficas_comparativas/estacionalidad_mensual.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=df, x='tipo_fondo', y='valor_unidad')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('data/graficas_comparativas/boxplot_tipos_fondo.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "fondo_ejemplo_vol = fondo_ejemplo.rolling(window=30).std()\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(fondo_ejemplo_vol.index, fondo_ejemplo_vol.values, color='red', alpha=0.7)\n",
        "plt.title('Volatilidad rolling (30 días) - Fondo moderado Skandia')\n",
        "plt.savefig('data/graficas_comparativas/volatilidad_rolling.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "pivot_corr = df.pivot_table(index='fecha', columns='tipo_fondo', values='valor_unidad', observed=False).corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(pivot_corr, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "plt.title('Correlación entre tipos de fondo')\n",
        "plt.tight_layout()\n",
        "plt.savefig('data/graficas_comparativas/correlacion_tipos_fondo.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(fondo_ejemplo.index, fondo_ejemplo.values, label='Valor diario', alpha=0.3)\n",
        "plt.plot(fondo_ejemplo.rolling(30).mean(), label='Media 30 días', linewidth=2)\n",
        "plt.plot(fondo_ejemplo.rolling(90).mean(), label='Media 90 días', linewidth=2)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('data/graficas_comparativas/analisis_tendencia.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(df.index, df['valor_unidad'], c=df['es_outlier'], cmap='coolwarm', alpha=0.6)\n",
        "plt.title('Identificación visual de outliers')\n",
        "plt.savefig('data/graficas_comparativas/outliers_detallado.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for tipo in df['tipo_fondo'].unique():\n",
        "    subset = df[df['tipo_fondo'] == tipo]\n",
        "    plt.hist(subset['valor_unidad'], bins=50, alpha=0.5, label=tipo, density=True)\n",
        "plt.legend()\n",
        "plt.title('Distribución de densidad por tipo de fondo')\n",
        "plt.savefig('data/graficas_comparativas/densidad_tipos_fondo.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "years = sorted(df['año'].dropna().unique())\n",
        "n_cols = 3\n",
        "n_rows = (len(years) + n_cols - 1) // n_cols\n",
        "Path('images/analisis_exploratorio').mkdir(parents=True, exist_ok=True)\n",
        "plt.figure(figsize=(15, 5 * n_rows))\n",
        "for i, year in enumerate(years, 1):\n",
        "    plt.subplot(n_rows, n_cols, i)\n",
        "    data_year = df[df['año'] == year]\n",
        "    for fondo in data_year['tipo_fondo'].unique():\n",
        "        data_fondo = data_year[data_year['tipo_fondo'] == fondo]\n",
        "        monthly_avg = data_fondo.groupby('mes')['valor_unidad'].mean()\n",
        "        plt.plot(monthly_avg.index, monthly_avg.values, marker='o', label=fondo)\n",
        "    plt.title(f'Evolución mensual {int(year)}')\n",
        "    plt.xticks(range(1, 13))\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    if i == 1:\n",
        "        plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/analisis_exploratorio/evolucion_mensual_por_año.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(\"EDA completado\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 15: Guardamos datasets procesados y listos para modelado con resumen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Exportes procesados listos\n"
          ]
        }
      ],
      "source": [
        "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "df.to_csv(\"data/processed/pensiones_limpio_final.csv\", index=False, encoding='utf-8')\n",
        "\n",
        "resumen_limpieza = {\n",
        "    'filas_finales': len(df),\n",
        "    'columnas_finales': len(df.columns),\n",
        "    'duplicados_eliminados': int(duplicados),\n",
        "    'outliers_detectados': int(len(outliers)),\n",
        "    'memoria_mb': df.memory_usage(deep=True).sum() / 1024**2,\n",
        "    'fecha_limpieza': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "pd.Series(resumen_limpieza).to_csv(\"data/processed/resumen_limpieza.csv\")\n",
        "\n",
        "df_modelado = df.dropna(subset=['valor_unidad', 'fecha', 'nombre_entidad', 'nombre_fondo']).copy()\n",
        "df_modelado.to_csv(\"data/processed/pensiones_listo_modelado.csv\", index=False, encoding='utf-8')\n",
        "print(\"✓ Exportes procesados listos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paso 16: Construimos y ejecutamos el pipeline de modelado ARIMA con evaluación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unterminated f-string literal (detected at line 8) (302685631.py, line 8)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(f\"\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated f-string literal (detected at line 8)\n"
          ]
        }
      ],
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def analizar_estacionariedad(serie, nombre_serie=\"\"):\n",
        "    print(f\"\n",
        "--- Análisis de Estacionariedad: {nombre_serie} ---\")\n",
        "    resultado_adf = adfuller(serie.dropna())\n",
        "    metricas = {\n",
        "        'estadistico_adf': resultado_adf[0],\n",
        "        'p_valor': resultado_adf[1],\n",
        "        'valores_criticos': resultado_adf[4],\n",
        "        'es_estacionaria': resultado_adf[1] < 0.05\n",
        "    }\n",
        "    print(f\"Estadístico ADF: {metricas['estadistico_adf']:.4f}\")\n",
        "    print(f\"P-valor: {metricas['p_valor']:.4f}\")\n",
        "    if metricas['es_estacionaria']:\n",
        "        print(\"✓ La serie ES estacionaria (p-valor < 0.05)\")\n",
        "    else:\n",
        "        print(\"✗ La serie NO es estacionaria (p-valor > 0.05)\")\n",
        "        print(\"  Se requiere diferenciación para modelado ARIMA\")\n",
        "    return metricas\n",
        "\n",
        "def entrenar_modelo_arima(serie, orden, nombre_serie=\"\"):\n",
        "    print(f\"Entrenando ARIMA{orden} para {nombre_serie}...\")\n",
        "    try:\n",
        "        modelo = ARIMA(serie, order=orden)\n",
        "        modelo_ajustado = modelo.fit()\n",
        "        metricas = {\n",
        "            'aic': modelo_ajustado.aic,\n",
        "            'bic': modelo_ajustado.bic,\n",
        "            'residuos_media': modelo_ajustado.resid.mean(),\n",
        "            'residuos_std': modelo_ajustado.resid.std()\n",
        "        }\n",
        "        print(f\"✓ ARIMA{orden} entrenado exitosamente\")\n",
        "        print(f\"  AIC: {metricas['aic']:.2f}, BIC: {metricas['bic']:.2f}\")\n",
        "        return modelo_ajustado, metricas\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error entrenando ARIMA{orden}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def buscar_mejor_arima(serie, parametros_a_probar, nombre_serie=\"\"):\n",
        "    print(f\"\n",
        "Buscando mejor modelo ARIMA para {nombre_serie}...\")\n",
        "    mejores_metricas = {'aic': float('inf')}\n",
        "    mejor_modelo = None\n",
        "    mejor_orden = None\n",
        "    for orden in parametros_a_probar:\n",
        "        modelo, metricas = entrenar_modelo_arima(serie, orden, nombre_serie)\n",
        "        if modelo and metricas and metricas['aic'] < mejores_metricas['aic']:\n",
        "            mejores_metricas = metricas\n",
        "            mejor_modelo = modelo\n",
        "            mejor_orden = orden\n",
        "    if mejor_modelo:\n",
        "        print(f\"\n",
        "🎯 MEJOR MODELO ENCONTRADO: ARIMA{mejor_orden} con AIC {mejores_metricas['aic']:.2f}\")\n",
        "        return {'modelo': mejor_modelo, 'orden': mejor_orden, 'metricas': mejores_metricas}\n",
        "    print(\"✗ No se pudo encontrar un modelo adecuado\")\n",
        "    return None\n",
        "\n",
        "def evaluar_pronostico(real, pronosticado, nombre_serie=\"\"):\n",
        "    print(f\"\n",
        "--- Evaluación de Pronósticos: {nombre_serie} ---\")\n",
        "    mse = np.mean((real - pronosticado)**2)\n",
        "    mae = np.mean(np.abs(real - pronosticado))\n",
        "    mape = np.mean(np.abs((real - pronosticado) / real)) * 100\n",
        "    rmse = np.sqrt(mse)\n",
        "    metricas = {'MSE': mse, 'MAE': mae, 'MAPE': mape, 'RMSE': rmse}\n",
        "    for k, v in metricas.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "    print(f\"  Error porcentual promedio (MAPE): {mape:.2f}%\")\n",
        "    return metricas\n",
        "\n",
        "def pipeline_modelado_completo(df_serie, nombre_serie, columna_valor='valor_unidad'):\n",
        "    print(f\"\n",
        "{'='*50}\n",
        "INICIANDO PIPELINE DE MODELADO: {nombre_serie}\n",
        "{'='*50}\")\n",
        "    resultados = {}\n",
        "    serie = df_serie.set_index('fecha')[columna_valor].sort_index()\n",
        "    resultados['serie_original'] = serie.copy()\n",
        "    resultados['estacionariedad'] = analizar_estacionariedad(serie, nombre_serie)\n",
        "    if not resultados['estacionariedad']['es_estacionaria']:\n",
        "        print(\"\n",
        "3. ⚙️  Aplicando diferenciación...\")\n",
        "        serie_diff = serie.diff().dropna()\n",
        "        resultados['serie_diferenciada'] = serie_diff\n",
        "        resultados['estacionariedad_diff'] = analizar_estacionariedad(serie_diff, f\"{nombre_serie} (diferenciada)\")\n",
        "        serie_para_modelar = serie_diff\n",
        "    else:\n",
        "        serie_para_modelar = serie\n",
        "    parametros_a_probar = [(1,0,0), (1,1,1), (2,1,2), (0,1,1), (1,1,0)]\n",
        "    resultados['mejor_modelo'] = buscar_mejor_arima(serie_para_modelar, parametros_a_probar, nombre_serie)\n",
        "    if resultados['mejor_modelo']:\n",
        "        modelo = resultados['mejor_modelo']['modelo']\n",
        "        train_size = int(len(serie_para_modelar) * 0.8)\n",
        "        train, test = serie_para_modelar[:train_size], serie_para_modelar[train_size:]\n",
        "        modelo_train = ARIMA(train, order=resultados['mejor_modelo']['orden']).fit()\n",
        "        pronostico = modelo_train.forecast(steps=len(test))\n",
        "        resultados['evaluacion'] = evaluar_pronostico(test.values, pronostico.values, nombre_serie)\n",
        "        print(\"\n",
        "6. 🔮 Generando pronósticos futuros...\")\n",
        "        pronostico_futuro = modelo.forecast(steps=30)\n",
        "        resultados['pronostico_futuro'] = pronostico_futuro\n",
        "        print(f\"Pronóstico 30 días: tendencia {'al alza' if pronostico_futuro.iloc[-1] > serie_para_modelar.iloc[-1] else 'a la baja'}\")\n",
        "    Path(\"data/modelos\").mkdir(parents=True, exist_ok=True)\n",
        "    resumen_modelado = {\n",
        "        'serie': nombre_serie,\n",
        "        'mejor_modelo': f\"ARIMA{resultados.get('mejor_modelo', {}).get('orden', 'N/A')}\",\n",
        "        'aic': resultados.get('mejor_modelo', {}).get('metricas', {}).get('aic', 'N/A'),\n",
        "        'estacionaria': resultados.get('estacionariedad', {}).get('es_estacionaria', False),\n",
        "        'mape': resultados.get('evaluacion', {}).get('MAPE', 'N/A')\n",
        "    }\n",
        "    pd.Series(resumen_modelado).to_csv(f\"data/modelos/resumen_{nombre_serie.replace(' ', '_').lower()}.csv\")\n",
        "    print(f\"✓ Pipeline de modelado completado para {nombre_serie}\")\n",
        "    return resultados\n",
        "\n",
        "series_a_modelar = {\n",
        "    \"Fondo Moderado Skandia\": df_skandia_pensiones_moderado,\n",
        "    \"Fondo Conservador Porvenir\": df_porvenir_pensiones_conservador,\n",
        "    \"Cesantías Largo Plazo Colfondos\": df_colfondos_cesantias_largo_plazo\n",
        "}\n",
        "\n",
        "resultados_modelado = {}\n",
        "for nombre_serie, df_serie in series_a_modelar.items():\n",
        "    if len(df_serie) > 100:\n",
        "        try:\n",
        "            resultados = pipeline_modelado_completo(df_serie, nombre_serie)\n",
        "            resultados_modelado[nombre_serie] = resultados\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error en modelado de {nombre_serie}: {e}\")\n",
        "    else:\n",
        "        print(f\"⚠️  Serie {nombre_serie} muy corta para modelado ({len(df_serie)} registros)\")\n",
        "\n",
        "if resultados_modelado:\n",
        "    comparacion_modelos = []\n",
        "    for nombre, resultados in resultados_modelado.items():\n",
        "        if resultados.get('mejor_modelo'):\n",
        "            comparacion_modelos.append({\n",
        "                'Serie': nombre,\n",
        "                'Mejor Modelo': f\"ARIMA{resultados['mejor_modelo']['orden']}\",\n",
        "                'AIC': resultados['mejor_modelo']['metricas']['aic'],\n",
        "                'Estacionaria': resultados['estacionariedad']['es_estacionaria'],\n",
        "                'MAPE (%)': resultados.get('evaluacion', {}).get('MAPE', 'N/A')\n",
        "            })\n",
        "    if comparacion_modelos:\n",
        "        df_comparacion = pd.DataFrame(comparacion_modelos)\n",
        "        print(\"\n",
        "📊 COMPARACIÓN DE MODELOS:\")\n",
        "        print(df_comparacion.to_string(index=False))\n",
        "        df_comparacion.to_csv(\"data/modelos/comparacion_modelos.csv\", index=False)\n",
        "\n",
        "        mejor_modelo = df_comparacion.loc[df_comparacion['AIC'].idxmin()]\n",
        "        print(f\"\n",
        "• Mejor modelo general: {mejor_modelo['Serie']} ({mejor_modelo['Mejor Modelo']})\")\n",
        "        print(f\"• AIC más bajo: {mejor_modelo['AIC']:.2f}\")\n",
        "        print(\"\n",
        "💡 Recomendaciones:\")\n",
        "        print(\"1. Para series estacionarias considerar modelos ARMA.\")\n",
        "        print(\"2. Para series no estacionarias explorar SARIMA estacional.\")\n",
        "        print(\"3. Revisar outliers cuando el MAPE sea alto.\")\n",
        "        print(\"4. Comparar con modelos de machine learning.\")\n",
        "\n",
        "Path(\"data/graficas_modelado\").mkdir(parents=True, exist_ok=True)\n",
        "for nombre_serie, resultados in resultados_modelado.items():\n",
        "    if resultados.get('mejor_modelo'):\n",
        "        try:\n",
        "            plt.figure(figsize=(15, 10))\n",
        "            plt.subplot(2, 2, 1)\n",
        "            serie_original = resultados['serie_original']\n",
        "            modelo = resultados['mejor_modelo']['modelo']\n",
        "            plt.plot(serie_original.index, serie_original.values, label='Original', alpha=0.7)\n",
        "            plt.plot(modelo.fittedvalues.index, modelo.fittedvalues, label='Ajustado', alpha=0.8)\n",
        "            plt.title(f'Serie Original vs Ajustada\n",
        "{nombre_serie}')\n",
        "            plt.legend()\n",
        "            plt.xticks(rotation=45)\n",
        "\n",
        "            plt.subplot(2, 2, 2)\n",
        "            residuos = modelo.resid\n",
        "            plt.plot(residuos.index, residuos.values)\n",
        "            plt.title('Residuos del Modelo')\n",
        "            plt.axhline(y=0, color='r', linestyle='--')\n",
        "            plt.xticks(rotation=45)\n",
        "\n",
        "            plt.subplot(2, 2, 3)\n",
        "            plt.hist(residuos.dropna(), bins=50, alpha=0.7, density=True)\n",
        "            plt.title('Distribución de Residuos')\n",
        "            plt.xlabel('Residuos')\n",
        "            plt.ylabel('Densidad')\n",
        "\n",
        "            plt.subplot(2, 2, 4)\n",
        "            if 'pronostico_futuro' in resultados:\n",
        "                pronostico = resultados['pronostico_futuro']\n",
        "                ultimos_30 = serie_original.tail(30)\n",
        "                plt.plot(ultimos_30.index, ultimos_30.values, label='Últimos 30 días', color='blue')\n",
        "                plt.plot(pronostico.index, pronostico.values, label='Pronóstico 30 días', color='red', linestyle='--')\n",
        "                plt.legend()\n",
        "            plt.title('Pronóstico a 30 días')\n",
        "            plt.xticks(rotation=45)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"data/graficas_modelado/resultados_{nombre_serie.replace(' ', '_').lower()}.png\", dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"✓ Gráficas guardadas para: {nombre_serie}\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error generando gráficas para {nombre_serie}: {e}\")\n",
        "\n",
        "print(\"\n",
        "PIPELINE DE MODELADO COMPLETADO ✓\")\n",
        "print(f\"Series modeladas: {len(resultados_modelado)}\")\n",
        "print(f\"Modelos generados: {sum(1 for r in resultados_modelado.values() if r.get('mejor_modelo'))}\")\n",
        "print(\"Resultados guardados en data/modelos/ y gráficas en data/graficas_modelado/\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
